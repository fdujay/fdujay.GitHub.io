---
layout:     post
title:      Rethinking Active Learning
subtitle:   主动学习在医学中的应用
date:       2020-06-26
author:     靳秋野
header-img: img/home-bg-art.jpg
catalog: true
tags:
    - Rethinking
---

参考博文：[周纵苇](http://www.zongweiz.com/)/[xinrui_zhuang](https://me.csdn.net/xinrui_zhuang)/[机器之心](https://mp.weixin.qq.com/s/qTZzQZEqHIJt_LAhYMd5lw)/[jiaotong_jin](https://blog.csdn.net/u013328485/article/details/96111113)
>
> 背景：目前推广应用的机器学习方法或模型主要解决分类问题，即给定一组数据（文本、图像、视频等），判断数据类别或将同类数据归类等，训练过程依赖于已标注类别的训练数据集。在实验条件下，这些方法或模型可以通过大规模的训练集获得较好的处理效果。然而在应用场景下，能够得到的数据实际上都没有进行人工标注处理，对这些数据进行类别标注所耗费的人力成本和时间成本非常巨大。在一些专门的应用领域，例如医学图像处理，只有专门学科的专业医生能够完成对医学影像图像的数据标注。显然，在这种情况下必须依赖大规模训练集才能使用的方法或模型都不再适用。

## 1. 简介

![img](https://raw.githubusercontent.com/fdujay/online_img/master/img/1689929-70c4a5d4d2cc8545.png)

为了减少对已标注数据的依赖，研究人员提出了主动学习（Active Learning）方法。主动学习通过某种策略找到未进行类别标注的样本数据中最有价值的数据，交由专家进行人工标注后，将标注数据及其类别标签纳入到训练集中迭代优化分类模型，改进模型的处理效果。

根据最有价值样本数据的获取方式区分，当前主动学习方法主要包括基于池的查询获取方法（query-acquiring/pool-based）和查询合成方法（query-synthesizing）两种。近年来提出的主动学习主要都是查询获取方法，即通过设计查询策略（抽样规则）来选择最具有价值信息的样本数据。与查询获取方法「选择（select）」样本的处理方式不同，查询合成方法「生成（generate）」样本。查询合成方法利用生成模型，例如生成式对抗网络（GAN, Generative Adversarial Networks）等，直接生成样本数据用于模型训练。

------

**问题背景：是不是训练数据集越多，深度学习的效果会越好呢？**

需要呈现的结果很简单，横坐标是训练集的样本数，纵坐标是分类的performance，如下图所示：

![img](https://raw.githubusercontent.com/fdujay/online_img/master/img/1689929-5e34911b5cdceaee.png)

> 图1-1 训练数据与性能的关系

如果答案是左图，那么就没什么可以说的了，去想办法弄到尽可能多的训练数据集就ok，但是现实结果是右图的红实线，一开始，训练集的样本数增加，分类器的性能快速地在上升，当训练集的样本数达到某一个临界值的时候，就基本不变了。

**也就是说，当达到了这个临界的数目时，再去标注数据的ground truth就是在浪费时间和金钱。**

> 这里需要说明的一点是，训练样本数的临界点大小和这个分类问题的难度有关，如果这个分类问题非常简单，如黑白图像分类（白色的是1，黑色的是0），那么这个临界值就特别小，往往几幅图就可以训练一个精度很高的分类器；如果分类问题很复杂，如判断一个肿瘤的良恶性（良性是0，恶性是1），那么这个临界值会很大，因为肿瘤的形状，大小，位置各异，分类器需要学习很多很多的样本，才能达到一个比较稳定的性能。

------

**解决思路：让数据饱和临界值变小，从而降低数据标注代价**

**本文用主动学习（Active Learning）的手段来挑选标注数据，从而找到一个更小的子集来达到最理想的性能。**主动学习（Active Learning），可以主动学习那些比较**“难的”**，**“信息量大的”**样本（hard mining）。关键点是每次都挑当前分类器分类效果不理想的那些样本（hard sample）给它训练，假设是训练这部分hard sample对于提升分类器效果最有效而快速。主动学习的核心问题，在于怎样**在不知道真正标签的情况下怎么去定义HARD sample？或者说怎么去描述当前分类器对于不同样本的分类结果的好坏？**之前的工作基本都是围绕这个问题展开的。

接下来，我们重点关注一下主动学习在医学图像处理中的应用，在第一篇文章中，我将会介绍得详细一些（补充基础知识），之后会将重点放在各方法的优缺点比较上面。


## 2. 应用（持续更新）

### *2.1 Fine-tuning Convolutional Neural Networks for Biomedical Image Analysis: Actively and Incrementally*

本篇论文发表于[CVPR2017](http://cvpr2017.thecvf.com/)，作者为美国亚利桑那州立大学着的在读博士生周纵苇。它主要解决的仍然是生物医学图像在用于深度学习时数据量过少的问题：如何使用尽可能少的标签数据来训练一个效果promising的分类器。作者提出了一个AIFT (active,incremental fine-tuning)网络，能够节约标注的时间和成本，把主动学习和迁移学习集成到一个框架。AIFT算法开始是直接使用一个预训练从未标注数据里找一些比较值得标注的样本，然后模型持续的加入新标注的数据，一直做微调。
AIFT方法是在CAD（计算机辅助诊断）系统的环境下使用，CAD可以生成候选集U，都是未标注数据，其中每一个候选样本（candidate）通过数据增强可以生成一系列的patches，由于这些patches来自于同一个候选样本，所以它们的标签跟该候选样本一致。

> 这与如今自监督学习中，对比监督方法类似，即来自相同样本的patches相似，不同样本的patches相异。

**定义：**由于深度学习的输出是属于某一类的概率（0～1），一个很直观的方法就是用“[熵（entropy）](https://en.wikipedia.org/wiki/Entropy)”来刻画信息量，把那些预测值模棱两可的样本挑出来，对于二分类问题，就是预测值越靠近0.5，它们的信息量越大。还有一个比较直观的方法是用“[多样性（diversity）](https://en.wikipedia.org/wiki/Diversity)”来刻画labeled data和unlabeled data的相似性。这两个方法都是在[“Active batch selection via convex relaxations with guaranteed solution bounds”](http://ieeexplore.ieee.org/abstract/document/7006697/)中被提出。是十分重要的两个Active Learning的选择指标。实验结果表明，与随机挑选相比，可以更快地达到临界拐点。

![img](https://raw.githubusercontent.com/fdujay/online_img/master/img/1689929-95bf7d0bd6942a4a.png)

> 图2-1-1 Active Learning的结构示意图。深度学习的优势在于，一开始你可以不需要有标记的数据集。

**实验效果：**

上述方法被应用在了**结肠镜视频帧分类**和**肺栓塞**检测上，得到了比较好的效果。前者只用了800个候选样本就达到了最好的表现，只用了5%的候选样本就代表了剩下的候选样本，因为连续的视频帧通常都差不多。后者使用了1000个样本就达到了`AlexNet`做Fine-tune使用2200个随机样本的效果。

------

**优点：**

- 从一个完全未标注的数据集开始，不需要初始的种子标注数据。

> 训练的初期不需要使用打好标签的数据对预训练的CNN模型进行训练，而是通过直接把未标注的数据导入预训练好的CNN网络中，得到预测值，挑出最难的，或者说是对于模型来说最不容易判断属于哪一类的图像来（文中采用的是熵和多样性的大小），人工打上标签再放进网络中进行训练。

- 通过持续的fine-tuning而不是重复的重新训练来一步一步改善学习器。

> 一开始标注数据集L是空的，我们拿一个已经训练好了的CNN（比如AlexNet），让它在未标注数据集U中选b个候选集来找医生标注，这新标注的候选集将会放到标注数据集L中，来持续的增量式fine-tune那个CNN直到合格，通过实验发现，持续的fine-tuning CNN相比在原始的预训练中重复性的fine-tuning CNN，可以让数据集收敛更快。

- 通过挖掘每一个候选样本的补丁的一致性来选择值得标注的候选集。

> 对每个候选样本，通过计算patch的熵和patch之间KL距离来衡量这个候选样本。如果熵越高，说明包含更多的信息，如果KL距离越大，说明patch间的不一致性大，所以这两个指标越高，越有可能对当前的CNN优化越大。对每个矩阵都可以生成一个包含patch的KL距离和熵的邻接矩阵R。

- 自动处理噪音（少数服从多数）。

> 对每个候选样本的所有patch，计算平均的预测概率，如果平均概率大于0.5，我们只选择概率最高的部分patch，如果概率小于0.5，选最低的部分patch，再基于已经选择的patch，来构建得分矩阵R。

- 只对每个候选集中小数量的补丁计算熵和KL距离，节约了计算，也大大节省了**计算损耗**。

**缺点：**

- 既然用了迁移学习，**那么一开始的CNN测试的效果肯定是一团糟**，因为这个CNN是从自然图像中学过来的，没有学习过CT这种医学影像，所以这个loop的启动阶段，Active Learning的效果会没有random selecting好。不过很快，随着CNN慢慢地在labeled的CT上训练，Active Learning的效果会一下子超过random selecting。

- 对于Continuous fine-tuning，随着labeled data集变大，CNN需要一次次地被训练，有两种选择，一是每次都从ImageNet pretrained来的model来迁移，二是每次用当前的model上面迁移(Continuous Fine-tuning)。方法一的优点是模型的参数比较好控制，因为每次都是从头开始fine-tuning，但是缺点是随着labeled数据量大增加，**GPU的消耗很大**，相当于每次有新的标注数据来的时候，就把原来的model扔了不管，在实际应用中的代价还是很大的。第二种方法是从当前的model基础上做fine tune，在某种意义上knowledge是有记忆的，而且是连续渐进式的学习。问题在于参数不好控制，例如learning rate，需要适当的减小，而且**比较容易在一开始掉入local minimum**。

------

### *2.2 Biomedical Image Segmentation via Representative Annotation*

本文发表在AAAI2019，作者均来自美国圣母大学，Lin Yang, YizheZhang, Jianxu Chen,均为华人，文章标题的中文翻译为：基于代表性注释的生物医学图像分割。在本文中，他们提出了一种新的深度学习框架：代表标注(Representative Annotation, RA)，以减少生物医学图像分割中的标注工作。本文使用三个数据集(两个2D和一个3D)评估我们的RA方法，并显示我们的框架与最先进的方法相比产生了有竞争力的分割结果。

**拟解决问题：**

深度学习已成功地应用于许多生物医学图像分割任务。然而，由于生物医学图像数据的多样性和复杂性，人工注释训练集费时费力，通常只有生物医学专家才能很好地注释图像数据。在主动学习类型的注释方案中，人类专家经常参与一个漫长的**迭代注释**(Iterative Process)过程。

**背景知识：**

目前，减轻注释负担的方法主要有两大类。**第一类的方法旨在通过利用弱/半监督学习方法来利用无注释的数据。**虽然这些方法很有前途，但其性能仍远未达到监督学习方法的水平。在生物医学分析中，准确性是非常重要的，因此性能是一个大问题。

![image-20200626225610030](https://raw.githubusercontent.com/fdujay/online_img/master/img/image-20200626225610030.png)

> 图2-2-1 不同数据集中的数据相似性例子。

第二类方法的目的是识别和注释对最终分割精度有贡献的最有价值的图像区域。为了达到这个目的，这些方法通常探究生物医学图像的以下两个特性。(1)某一类应用的生物医学图像通常是相似的(如腺体分割、心脏分割)。因此，在生物医学图像数据集中可能存在大量的冗余。图2-2-1(a)和(c)分别显示了腺体和心脏CT图像的一些常见模式。(2)虽然生物医学图像中感兴趣区域(ROIs)可能有不同的外观，但我们注意到它们可以大致分为一定数量的组(如图2-2-1(b))。因此，选择具有代表性的样本来覆盖不同的情况，有助于获得良好的分割性能。

**使用方法：**

主动学习可以从未标记的集合中选择信息样本，并指导人类专家查询标签。本文提出了新的主动学习模型，直接选择具有较高影响和多样性的有效实例进行生物医学图像的一次性分割(即one-shot，没有迭代过程，只训练DL模型一次)。

要实现一次性选择，我们需要应对两大挑战：

1. 与AL中模型可以进行人工标注，可以通过监督训练来提取信息特征相比，我们框架中的图像特征提取组件只有原始图像数据，只能进行无监督训练。

2. 所有的AL方法主要依赖于未标注图像的不确定性估计(uncertainty estimation)，我们的框架中没有用到。相反，我们需要为有价值的ROIs制定一个新的标准。

针对这些问题，本文提出了一种新的数据挖掘框架——代表性标注(representative annotation, RA)，使用无监督网络进行特征提取，在学习的特征描述子的潜在空间中选择有代表性的图像块进行标注，在最小化冗余的同时隐式地表征底层数据。具体来说，我们利用基于聚类的方法来减少集群内冗余，并利用最大覆盖(`Max-cover`)方法来减少集群间冗余，而不牺牲集群间的多样性。以这种方式，选取具有代表性的图像样本。图2-2-2概述了我们的主要思想和步骤。此外，**我们的One-shot框架实现了对3D图像的高效注释选择**。最后，带注释的选定图像patch训练一个全卷积网络(FCN)进行图像分割。

<img src="https://raw.githubusercontent.com/fdujay/online_img/master/img/image-20200626233012850.png" alt="image-20200626233012850" style="zoom:80%;" />

> 图2-2-2 RA模型的基本流程

**优点：**

我们的RA方案有三个引人注目的优点:

1. 它利用了深度神经网络学习图像数据更好表示的能力;

2. 需要手动注释的样本一次性(One-shot)选择，使注释者从以往常见的迭代注释过程中解放出来；

3. 通过简单的扩展可以部署到3D图像中。

**缺点：**

- 实际上，主动学习虽然可以挑选比较有代表性的数据进行标注，但是也浪费了大量无标注数据信息（信息损失）；如果可以同时利用无标注数据，那么可以提高模型的鲁棒性。



